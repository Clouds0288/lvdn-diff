{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12eb8182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded raw data. Samples: 50016\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports & Setup\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandapower as pp\n",
    "import pandapower.networks as pn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data # PyG çš„æ ¸å¿ƒæ•°æ®ç»“æ„\n",
    "\n",
    "# è·¯å¾„é…ç½®\n",
    "RAW_PATH = \"../data/processed/cigre_lv_stress_test_v1.pt\"\n",
    "SAVE_PATH = \"../data/processed/cigre_lv_graph_dataset_v1.pt\"\n",
    "\n",
    "# åŠ è½½åŸå§‹ Tensor æ•°æ®\n",
    "if not os.path.exists(RAW_PATH):\n",
    "    raise FileNotFoundError(f\"âŒ Raw data not found at {RAW_PATH}. Run Notebook 01 first!\")\n",
    "\n",
    "raw_data = torch.load(RAW_PATH)\n",
    "X_raw = raw_data['X'].numpy()      # [N, 3] (P_tot, Q_tot, Time)\n",
    "Y_v_raw = raw_data['Y_v'].numpy()  # [N, Nodes]\n",
    "Y_p_raw = raw_data['Y_p'].numpy()  # [N, Nodes]\n",
    "\n",
    "print(f\"âœ… Loaded raw data. Samples: {X_raw.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ce51fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping Check: Found 15 loads mapping to 44 buses.\n",
      "ğŸ”— Corrected Topology:\n",
      "   Nodes: 44 (Expected 44)\n",
      "   Load Map indices: [2, 12, 16, 17, 18, 19, 22, 24, 35, 36, 37, 40, 41, 42, 43]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Topology & Mapping Logic (FIXED)\n",
    "\n",
    "def extract_graph_and_mapping(raw_y_p_dim):\n",
    "    # 1. åˆ›å»ºç½‘ç»œä»¥è·å–æ‹“æ‰‘\n",
    "    net = pn.create_cigre_network_lv()\n",
    "    \n",
    "    # --- A. å»ºç«‹èŠ‚ç‚¹æ˜ å°„ (Bus ID -> 0..43 Index) ---\n",
    "    bus_ids = net.bus.index.values\n",
    "    # è¿™æ˜¯ä¸€ä¸ª lookup table: çœŸå® Bus ID -> è¿ç»­çš„ 0~43 ç´¢å¼•\n",
    "    bus_mapper = {b_id: i for i, b_id in enumerate(bus_ids)}\n",
    "    n_nodes = len(bus_ids)\n",
    "    \n",
    "    # --- B. å»ºç«‹è´Ÿè·æ˜ å°„ (Load Index -> Bus Index) ---\n",
    "    # æˆ‘ä»¬ç°åœ¨çš„ Y_p æ˜¯ (N, 15)ï¼Œæ¯ä¸€åˆ—å¯¹åº” net.load è¡¨çš„ä¸€è¡Œ\n",
    "    # æˆ‘ä»¬éœ€è¦çŸ¥é“ net.load çš„ç¬¬ i è¡Œè¿åœ¨å“ªä¸ª Bus ä¸Š\n",
    "    load_bus_ids = net.load.bus.values # çœŸå®çš„ Bus ID\n",
    "    # å°† Load è¿æ¥çš„ Bus ID è½¬æ¢ä¸º 0~43 çš„ç´¢å¼•\n",
    "    load_to_bus_idx = [bus_mapper[b_id] for b_id in load_bus_ids]\n",
    "    \n",
    "    print(f\"Mapping Check: Found {len(load_to_bus_idx)} loads mapping to {n_nodes} buses.\")\n",
    "    # ç¡®ä¿ç»´åº¦åŒ¹é… (ç”Ÿæˆçš„ Y_p åº”è¯¥å’Œ net.load é•¿åº¦ä¸€è‡´)\n",
    "    if len(load_to_bus_idx) != raw_y_p_dim:\n",
    "        raise ValueError(f\"Mismatch! Data has {raw_y_p_dim} loads, but topology has {len(load_to_bus_idx)}.\")\n",
    "\n",
    "    # --- C. æå–è¾¹ (Edges) ---\n",
    "    src = [bus_mapper[b] for b in net.line.from_bus.values]\n",
    "    dst = [bus_mapper[b] for b in net.line.to_bus.values]\n",
    "    \n",
    "    # æå–ç‰©ç†å‚æ•° (R, X)\n",
    "    r_ohm = net.line.r_ohm_per_km.values * net.line.length_km.values\n",
    "    x_ohm = net.line.x_ohm_per_km.values * net.line.length_km.values\n",
    "    \n",
    "    # å˜å‹å™¨è¾¹\n",
    "    t_src = [bus_mapper[b] for b in net.trafo.hv_bus.values]\n",
    "    t_dst = [bus_mapper[b] for b in net.trafo.lv_bus.values]\n",
    "    t_r = np.array([0.001] * len(net.trafo))\n",
    "    t_x = np.array([0.01] * len(net.trafo))\n",
    "    \n",
    "    # æ„å»ºåŒå‘å›¾\n",
    "    final_src = src + t_src + dst + t_dst\n",
    "    final_dst = dst + t_dst + src + t_src\n",
    "    final_r = np.concatenate([r_ohm, t_r, r_ohm, t_r])\n",
    "    final_x = np.concatenate([x_ohm, t_x, x_ohm, t_x])\n",
    "    \n",
    "    edge_index = torch.tensor([final_src, final_dst], dtype=torch.long)\n",
    "    edge_attr = torch.tensor(np.stack([final_r, final_x], axis=1), dtype=torch.float)\n",
    "    \n",
    "    return edge_index, edge_attr, load_to_bus_idx, n_nodes\n",
    "\n",
    "# æ‰§è¡Œæå–\n",
    "# æ³¨æ„ï¼šX_raw ç­‰å˜é‡éœ€è¦æ¥è‡ª Cell 1 çš„åŠ è½½\n",
    "# Y_p_raw.shape[1] åº”è¯¥æ˜¯ 15\n",
    "edge_index, edge_attr, load_map, n_nodes = extract_graph_and_mapping(Y_p_raw.shape[1])\n",
    "\n",
    "print(f\"ğŸ”— Corrected Topology:\")\n",
    "print(f\"   Nodes: {n_nodes} (Expected 44)\")\n",
    "print(f\"   Load Map indices: {load_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf67b236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding Power Injections to Full Bus Matrix...\n",
      "   Expansion done. Y_p shape: (50016, 44)\n",
      "ğŸ“Š Final Data Shapes:\n",
      "   Y_v (Voltage): torch.Size([50016, 44]) (Should be N, 44)\n",
      "   Y_p (Power):   torch.Size([50016, 44]) (Should be N, 44)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Expand Power Injections & Normalization\n",
    "\n",
    "def process_and_scale(X, Y_v, Y_p_sparse, load_map, n_nodes):\n",
    "    \"\"\"\n",
    "    Y_p_sparse: [N, 15] -> åªæœ‰è´Ÿè·ç‚¹çš„åŠŸç‡\n",
    "    load_map: [15] -> è´Ÿè·ç‚¹å¯¹åº”çš„èŠ‚ç‚¹ç´¢å¼•\n",
    "    target: [N, 44] -> å…¨ç½‘èŠ‚ç‚¹åŠŸç‡ (éè´Ÿè·ç‚¹å¡« 0)\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    # 1. æ‰©å±•åŠŸç‡çŸ©é˜µ (Map 15 cols to 44 cols)\n",
    "    print(\"Expanding Power Injections to Full Bus Matrix...\")\n",
    "    Y_p_full = np.zeros((n_samples, n_nodes), dtype=np.float32)\n",
    "    \n",
    "    # å°†ç¨€ç–çš„è´Ÿè·æ•°æ®å¡«å…¥å¯¹åº”çš„èŠ‚ç‚¹åˆ—\n",
    "    # Y_p_sparse[:, i] æ˜¯ç¬¬ i ä¸ªè´Ÿè·çš„æ‰€æœ‰æ ·æœ¬æ•°æ®\n",
    "    # load_map[i] æ˜¯ç¬¬ i ä¸ªè´Ÿè·æ‰€åœ¨çš„èŠ‚ç‚¹ç´¢å¼•\n",
    "    for i, bus_idx in enumerate(load_map):\n",
    "        Y_p_full[:, bus_idx] = Y_p_sparse[:, i]\n",
    "        \n",
    "    print(f\"   Expansion done. Y_p shape: {Y_p_full.shape}\")\n",
    "\n",
    "    # 2. åˆ’åˆ†æ•°æ®é›†\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx = indices[:int(0.8*n_samples)]\n",
    "    val_idx = indices[int(0.8*n_samples):int(0.9*n_samples)]\n",
    "    test_idx = indices[int(0.9*n_samples):]\n",
    "    \n",
    "    # 3. æ ‡å‡†åŒ– (Scaling)\n",
    "    # åªåœ¨ Train ä¸Š fit\n",
    "    scaler_x = StandardScaler().fit(X[train_idx, :2])\n",
    "    scaler_y_v = StandardScaler().fit(Y_v[train_idx])\n",
    "    scaler_y_p = StandardScaler().fit(Y_p_full[train_idx]) # ç°åœ¨æ˜¯å¯¹ 44 åˆ—åš scaling\n",
    "    \n",
    "    # Transform\n",
    "    X_norm = X.copy()\n",
    "    X_norm[:, :2] = scaler_x.transform(X[:, :2])\n",
    "    Y_v_norm = scaler_y_v.transform(Y_v)\n",
    "    Y_p_norm = scaler_y_p.transform(Y_p_full)\n",
    "    \n",
    "    # è½¬ Tensor\n",
    "    return (torch.from_numpy(X_norm).float(),\n",
    "            torch.from_numpy(Y_v_norm).float(),\n",
    "            torch.from_numpy(Y_p_norm).float(),\n",
    "            train_idx, val_idx, test_idx,\n",
    "            {'x': scaler_x, 'y_v': scaler_y_v, 'y_p': scaler_y_p})\n",
    "\n",
    "# æ‰§è¡Œå¤„ç†\n",
    "X_norm, Y_v_norm, Y_p_norm, train_idx, val_idx, test_idx, scalers = \\\n",
    "    process_and_scale(X_raw, Y_v_raw, Y_p_raw, load_map, n_nodes)\n",
    "\n",
    "print(f\"ğŸ“Š Final Data Shapes:\")\n",
    "print(f\"   Y_v (Voltage): {Y_v_norm.shape} (Should be N, 44)\")\n",
    "print(f\"   Y_p (Power):   {Y_p_norm.shape} (Should be N, 44)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca2267ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved corrected dataset.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Save\n",
    "processed_data = {\n",
    "    \"edge_index\": edge_index,\n",
    "    \"edge_attr\": edge_attr,\n",
    "    \"X\": X_norm,\n",
    "    \"Y_v\": Y_v_norm,\n",
    "    \"Y_p\": Y_p_norm,\n",
    "    \"train_idx\": torch.from_numpy(train_idx),\n",
    "    \"val_idx\": torch.from_numpy(val_idx),\n",
    "    \"test_idx\": torch.from_numpy(test_idx),\n",
    "    \"scalers\": scalers,\n",
    "    \"n_nodes\": n_nodes\n",
    "}\n",
    "torch.save(processed_data, SAVE_PATH)\n",
    "print(\"âœ… Saved corrected dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66e2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lvdn-diff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
